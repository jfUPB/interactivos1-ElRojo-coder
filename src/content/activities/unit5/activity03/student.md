Cuando el micro:bit envía datos a una aplicación receptora, inicialmente lo hace en formato de texto utilizando el protocolo ASCII. Esto significa que los valores transmitidos —por ejemplo, lecturas de sensores o estados de botones— se representan como cadenas de caracteres legibles, como "123,-456,True,False". Aunque este formato es fácil de entender para una persona, puede resultar visualmente confuso si los datos se actualizan rápidamente o si el volumen de información es alto, dificultando así su lectura en tiempo real.

Al cambiar la visualización a formato hexadecimal (HEX), los mismos datos se muestran de forma más compacta, lo que evidencia una codificación distinta. Aquí, los datos se representan como secuencias de valores numéricos en base 16, derivados directamente de su codificación binaria. Este formato es mucho más eficiente desde el punto de vista computacional, ya que ocupa menos espacio y se transmite con mayor rapidez y menor carga para el sistema.

Este contraste entre ASCII y binario nos permite observar las diferencias clave entre un enfoque orientado a la legibilidad humana y otro enfocado en la eficiencia de la máquina. El formato ASCII es más extenso porque cada carácter requiere múltiples bits para representarse. Por ejemplo, el número "-123" implica al menos cuatro caracteres: el signo negativo y tres dígitos, lo que se traduce en varios bytes. En cambio, en binario ese mismo valor puede codificarse con solo dos bytes o incluso menos, dependiendo del tipo de dato utilizado.

No obstante, el uso de ASCII tiene una ventaja significativa cuando se desea monitorear o depurar los datos directamente, ya que los números y palabras se pueden leer sin necesidad de decodificarlos. Esto es especialmente útil cuando los valores incluyen signos, como positivos y negativos, o cuando se trabaja con información lógica como "True" o "False", lo que facilita identificar patrones o problemas de inmediato.

Por otro lado, el formato binario es ideal cuando se busca optimizar el rendimiento del sistema, reducir el uso de memoria y acelerar la velocidad de transmisión, factores especialmente relevantes en sistemas embebidos o de tiempo real como el micro:bit. Al representar los datos en binario, se eliminan los caracteres extra y se logra una mayor eficiencia, aunque a costa de dificultar la lectura directa.

En conclusión, cada formato tiene su propósito: ASCII es ideal para la comprensión humana y la depuración, mientras que el binario (y su representación en hexadecimal) está diseñado para maximizar la eficiencia en la transmisión de datos. Comprender esta dualidad es fundamental para diseñar sistemas de comunicación serial robustos y adecuados al contexto de uso.
